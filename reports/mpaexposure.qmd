---
title: "MPA Exposure Analysis"
format: 
  html:
    code-fold: true
editor: visual
---

```{r}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

------------------------------------------------------------------------

Code to characterize exposure of California MPAs to future pH, DO, and temperature using IPSL model predictions. Note: this setup is only for one projection (IPSL). Change every occurence of "IPSL" to "GFDL" or "HADLEY" in this report to do same for diff projection.

## Setup

Load libraries and read data. Convert DO units and filter for years 2090-2100.

```{r}
#| label: libraries
#| message: false

library(tidyverse)
library(lubridate)
library(data.table)
library(factoextra)
library(broom)
library(cowplot)
library(respR)
library(here)
library(lattice)
library(RcppRoll)
library(RColorBrewer)
library(gplots)
library(ggpmisc)
library(dendextend)
library(colourvalues)
library(zoo)
library(terra) #needed for tmap?
library(tmap) 
library(sf) 
```

Load MPA name file and merge with model projection. Add time periods.

```{r}
#| label: load_data
#| message: false

#Read mpa data, convert DO units, add a column for time period, and one for difference between mid/end cen and historic.
mpa <- read_csv(here("data/processeddata/model/IPSLmpa.csv")) %>% 
  mutate(DO_mmolL = DO_surf/1000,
         DO_mgL = convert_DO(DO_mmolL, from = "mmol/L", to = "mg/L")) %>% 
  filter(Year <= 2020|
         Year >= 2040 & Year <= 2060|
         Year >= 2080 & Year <= 2100) %>%
  mutate(period = case_when((Year <= 2020) ~ "historic", 
                           (Year %in% c(2040:2060)) ~ "midcen",
                           (Year %in% c(2080:2100)) ~ "endcen")) %>%
  select(-T_bot, -DO_bot, -pH_bot,-DO_surf,-DO_mmolL) %>%
  rename(Temp = T_surf,
         DO = DO_mgL,
         pH = pH_surf) %>%
  mutate(Date = make_date(Year, Month, Day)) %>%
  mutate(julianday = yday(Date))

mpa$File <- substr(mpa$File, 1, nchar(mpa$File)-4)

```

Add regions

```{r}
#| label: regions
#| message: false
#add regions here!
mpa_centroids<- read_csv(here("data/rawdata/MPA_polygons.csv")) %>%
  select(-Area_sq_mi, -Type)
mpa_centroids$File <- sub("^", "tphdo_mpa_", mpa_centroids$OBJECTID )

mpa_centroids <- mpa_centroids %>%
  mutate(region = ifelse(degy >= 37.29, "norca", 
                         ifelse(degy > 34.8, "centralca", 
                                ifelse("degy" < 34.274 & "degx" < -119.220, "channelisl" , 
                                       "socal"))))

channel <- c("Anacapa Island FMCA", "Anacapa Island FMR", "Anacapa Island SMCA", "Anacapa Island SMR", "Anacapa Island Special Closure", 
             "Arrow Point to Lion Head Point SMCA", "Begg Rock SMR", "Blue Cavern Offshore SMCA", "Blue Cavern Onshore SMCA (No-Take)", 
             "Carrington Point SMR", "Casino Point SMCA (No-Take)", "Cat Harbor SMCA", "Farnsworth Offshore SMCA", "Farnsworth Onshore SMCA", 
             "Footprint FMR", "Footprint SMR", "Gull Island FMR", "Gull Island SMR", "Harris Point FMR", "Harris Point SMR", "Judith Rock SMR", 
             "Long Point SMR", "Loverâ€™s Cove SMCA", "Painted Cave SMCA", "Richardson Rock FMR", "Richardson Rock SMR", "San Miguel Island Special Closure", 
             "Santa Barbara Island FMR", "Santa Barbara Island SMR", "Scorpion FMR", "Scorpion SMR", "Skunk Point SMR", "South Point FMR", "South Point SMR")

mpa_centroids$region[mpa_centroids$NAME %in% channel]  <- "channel" 
mpa <- merge(mpa, mpa_centroids,  by = "File")

```

## Calculate climatology

Create a climatology (Jan averaged over every year), so each MPA has one value per month that is averaged over all of the years. Find SD of this dataframe, to get seasonal variation.

```{r}
#| label: clim_SD
#| message: false

#calculate climatology for each MPA for each time period
mpa_climatology <- mpa %>%
  group_by(File, Month, period) %>%
    summarise(T_clim = mean(Temp), 
              pH_clim = mean(pH), 
              DO_clim =   mean(DO))


#individual files per time period 
mpa_historic_climatology <- mpa %>% 
  filter(period == "historic") %>%
  group_by(File, Month) %>%
  summarise(T_clim = mean(Temp), T_clim_sd = sd(Temp), pH_clim = mean(pH), DO_clim =   mean(DO))

mpa_midcen_climatology <- mpa %>%
  filter(period == "midcen") %>%
  group_by(File, Month) %>%
  summarise(T_clim = mean(Temp), pH_clim = mean(pH), DO_clim = mean(DO))

mpa_endcen_climatology <- mpa %>%
  filter(period == "endcen") %>%
  group_by(File, Month) %>%
  summarise(T_clim = mean(Temp), pH_clim = mean(pH), DO_clim = mean(DO))

```

## Calculate event-based variation

Create a mock dataset interpolating climatologies to get daily values in the absence of natural event-based variability. Subtract actual daily values. Find standard deviation of these differences (on a daily scale).

**Setup for interpolation:**

Need to create a day1 and day365 proxies. Approx function can only interpolate not extrapolate so without this, you can't interpolate days 1-14 and 350-365.

```{r}
#| label: inter_setup
#| message: false
#| warning: false

##below creates empty vectors as big as we need (365 days per mpa) for each variable and each mpa. julianday is dates 1-365 as many mpa times

mpaslist = unique(mpa$File) 
mpas = rep(NA, 365*121)
julianday = rep(1:365, 121)
interp = rep(NA, 365*121)

#Set up a vector of julian day assignment for the 15th of each month and the first and last day of the year
x_in <- yday(as.Date(c("2001-01-01", 
                       "2001-01-15","2001-02-15","2001-03-15","2001-04-15",
                       "2001-05-15","2001-06-15","2001-07-15","2001-08-15",
                       "2001-09-15","2001-10-15","2001-11-15","2001-12-15", 
                       "2001-12-31")))

# creating a list of all the days of the year to interpolate to.
x_out <- (1:365) 

```

Function to interpolate julian days (1-365) per MPA per variable and time period

```{r}
interpolate <- function(periodt, variable){
  
  mpa_period_climatology <- mpa_climatology %>%
    filter(period == periodt)
  
  for (i in 1:length(mpaslist)){
    
    d <- mpa_period_climatology %>% 
      filter(File == mpaslist[i]) %>% 
      select(File,Month, !!sym(variable))
    
#use a weighted average. for dec 31, slightly more than half weight to dec, little less than   half weight to jan. for jan 1, slightly more weight to jan, little less weight to dec
    Dec31 = as.numeric(( ((16/30) * (d[12,3])) + 
                           ((14/30) * d[1,3]) )) 
    Jan1 = as.numeric(( ((14/30) * (d[12,3])) + 
                          ((16/30) * d[1,3]) ))

    y_in <- c(Jan1, d[[variable]], Dec31)
    
    mod <- approx(x = x_in, #days to interpolate from
                 y = y_in, #temp values per day in x_in
                 xout = x_out) #1-365 days to interpolate out to
    
    #I don't understand this part
    mpas[((i-1)*365+1):(i*365)] <- mpaslist[i] #rep(mpaslist[1], 365)
    interp[((i-1)*365+1):(i*365)] <- mod$y
  }
  
  df <- data.frame(mpas, julianday, interp) %>%
    rename(File = mpas) %>%
    mutate(period = periodt) %>%
    rename(!!sym(variable) := interp)
  
  assign(x = paste("interp",variable,periodt, sep="_"), value = df, envir = globalenv())
  
}

interpolate("historic", "T_clim")
interpolate("midcen", "T_clim")
interpolate("endcen", "T_clim")

interpolate("historic", "pH_clim")
interpolate("midcen", "pH_clim")
interpolate("endcen", "pH_clim")

interpolate("historic", "DO_clim")
interpolate("midcen", "DO_clim")
interpolate("endcen", "DO_clim")
```

Combine time periods into one df

```{r}
interpolated_temp <- rbind(interp_T_clim_historic,
                           interp_T_clim_midcen,
                           interp_T_clim_endcen)

interpolated_pH <- rbind(interp_pH_clim_historic,
                           interp_pH_clim_midcen,
                           interp_pH_clim_endcen)

interpolated_DO <- rbind(interp_DO_clim_historic,
                           interp_DO_clim_midcen,
                           interp_DO_clim_endcen)
```

## Create summary stats

Merge interpolated values to MPA dataset to find seasonal SD (SD of deviation between daily value and interpolated climatological value). Add other summary stats like event SD, mean, lower 10, upper 10 percentile.

```{r}
#| label: summary_stats

#calculate seasonal SD 
seasonal_SD <- mpa_climatology %>%
  group_by(File, period) %>%
  summarise(T_seasonalSD = sd(T_clim),
            pH_seasonalSD = sd(pH_clim),
            DO_seasonalSD = sd(DO_clim))

#put all summary stats together
sum <- mpa %>%
 
  #merge interpolated climatologies to mpa. (used to calculate event sd)
  merge(interpolated_temp, by = c("File", "julianday", "period")) %>%
  merge(interpolated_pH, by = c("File", "julianday", "period")) %>%
  merge(interpolated_DO, by = c("File", "julianday", "period")) %>%
  
  #subtract actual values - interpolated climatology values 
  #filtered for only upwelling months!!
  mutate(temp_deviation = Temp - T_clim,
         pH_deviation = pH - pH_clim,
         DO_deviation = DO - DO_clim) %>%
  filter(Month == c(5,6,7,8,9)) %>%
  
  #find event based SD 
  group_by(File, period) %>%
    mutate(T_eventSD = sd(temp_deviation),
            pH_eventSD = sd(pH_deviation),
            DO_eventSD = sd(DO_deviation)) %>%
  ungroup() %>%
    select(-T_clim, -pH_clim, -DO_clim, -temp_deviation,
         -pH_deviation, -DO_deviation) %>%
  
    #merge seasonal SD 
    merge(seasonal_SD, by = c("File", "period")) %>%
  
    #adding other summary stats - mean, low 10th and upper 10th percentiles
    group_by(File, period) %>%
    mutate(across(c(Temp, DO, pH), 
                   list(mean = mean, 
                        low10 = ~ quantile(.x, 0.1),
                        high10 = ~quantile(.x,0.9)))) %>%
  
  # to get to scale of one row per mpa
  select(-...1, -Temp, -pH, -DO, -julianday, -Year, -Month, -Day) %>%
  distinct(File, .keep_all = TRUE) %>% ungroup()

```

## PCA

PCA with all summary stats (mean, lower 10th percentile, seasonal SD, event SD)

```{r}
#| label: pca


make_pca <- function(df, periodt){
  sum_period <- df %>% filter(period == periodt) 
  sumsub <- sum_period %>% select(-OBJECTID,-NAME, -File, -SHORTNAME, -degx, 
                                  -degy, -region, -period, -Date) 
  
  pca <- prcomp(sumsub, scale = TRUE)
  
  plot <- fviz_pca_biplot(pca, repel = TRUE,
                  col.var = "black",
                  col.ind = sum_period$region,
                  label ="var",
                  labelsize = 3,
                  addEllipses = TRUE,
                  title = periodt) 
  #fviz_pca_ind(pca, label="none", habillage=sum_period$region,
               #addEllipses=TRUE,  col.ind = sum_period$region)
  
  ggsave(here(paste("./figs/pca/pca",periodt,".png")), plot)
}

make_pca(sum, "historic")
make_pca(sum, "midcen")
make_pca(sum, "endcen") #need to rotate by changing sumsub to sumsub[,-1] inside prcomp


```

## Heatmaps by variable

```{r}

col <- colorRampPalette(brewer.pal(9,"YlOrRd"))(256)
invert_col <- colorRampPalette(rev(brewer.pal(9,"YlOrRd")))(256)


make_heatmap <- function(sumstat, color_palette = invert_col){
  
  #make matrix for variable of interest
  matrix <- sum %>%
  select(!!sym(sumstat), NAME, degy, period, region) %>%
  pivot_wider(names_from = period, values_from = sumstat) %>%
  mutate(col = case_when((region == "centralca") ~ "#ffff99", 
                             (region == "norca") ~ "#beaed4",
                             (region == "socal") ~ "#fdc086",
                             (region == "channel") ~ "#7fc97f")) %>%
  arrange(degy) 

  #making matrix numeric for heatmap to work
  matrix_numeric <- matrix %>%
  select(-NAME, -region, -degy, -col) %>%
  select(historic, midcen, endcen) %>%
  as.matrix()

  row.names(matrix_numeric) <- matrix$NAME

  jpeg(file=here(paste("./figs/heatmap/heatmap",sumstat,".jpeg", 
                       sep = "_")), res = 100)
  
  heatmap.2(matrix_numeric, Rowv = FALSE, Colv = FALSE, dendrogram = "none", 
          main = sumstat, tracecol=NA, revC= TRUE,
          margins = c(3,7), col= color_palette, srtCol = 360, 
          labRow = matrix$NAME, RowSideColors = matrix$col, cexRow = 0.5,
          cexCol = 1)
  dev.off()

}

#Temp heatmaps
make_heatmap("Temp_mean", col)
make_heatmap("Temp_high10", col)
make_heatmap("Temp_low10", col)
make_heatmap("T_eventSD", col)
make_heatmap("T_seasonalSD", col)

#pH heatmaps
make_heatmap("pH_mean")
make_heatmap("pH_high10")
make_heatmap("pH_low10")
make_heatmap("pH_eventSD")
make_heatmap("pH_seasonalSD")

#DO heatmaps
make_heatmap("DO_mean")
make_heatmap("DO_high10")
make_heatmap("DO_low10")
make_heatmap("DO_eventSD")
make_heatmap("DO_seasonalSD")

```

## Regressions

Supplementing heatmaps by looking at correlation between historic and future time periods for a given summary stat

```{r}

make_regression <- function(sumstat, period1, period2){
 plot_matrix <- sum %>%
   filter(period == period1 | period == period2) %>%
   select(sumstat, period, NAME, File) %>%
   pivot_wider(names_from = period, values_from = sumstat) 
 
 plot <- ggplot(data = plot_matrix, aes_string(x = period1, y = period2)) +
   stat_poly_line() +
   stat_poly_eq(use_label(c("eq", "R2"))) +
   geom_point() +
   theme_classic() +
   ggtitle(sumstat)
 
  ggsave(here(paste("./figs/regression/regression",sumstat,period2,".png")), plot)

}

    #temp
    make_regression("Temp_mean", "historic", "midcen")
    make_regression("Temp_mean", "historic", "endcen")
    make_regression("T_seasonalSD", "historic", "midcen")
    make_regression("T_seasonalSD", "historic", "endcen")
    make_regression("T_eventSD", "historic", "midcen")
    make_regression("T_eventSD", "historic", "endcen")
    
    #pH
    make_regression("pH_mean", "historic", "midcen")
    make_regression("pH_mean", "historic", "endcen")
    make_regression("pH_seasonalSD", "historic", "midcen")
    make_regression("pH_seasonalSD", "historic", "endcen")
    make_regression("pH_eventSD", "historic", "midcen")
    make_regression("pH_eventSD", "historic", "endcen")
    
    #DO
    make_regression("DO_mean", "historic", "midcen")
    make_regression("DO_mean", "historic", "endcen")
    make_regression("DO_seasonalSD", "historic", "midcen")
    make_regression("DO_seasonalSD", "historic", "endcen")
    make_regression("DO_eventSD", "historic", "midcen")
    make_regression("DO_eventSD", "historic", "endcen")

```

## Anomalous pH/DO Event Analysis

Find percentage of unsaturated/ low DO days over all years using a biological threshold. Separated by upwelling and non-upwelling months. Output is used to make maps in QGIS.

```{r}
# Create labels for events (e.g., consecutive days with low pH or low DO) using run 
# length encoding

label_events <- function(is_event) {
  event_rle <- rle(is_event)
  labels <- ifelse(event_rle$values, cumsum(event_rle$values), NA)
  rep(labels, event_rle$lengths)
}

#all event categorization for pH and DO
events <- mpa %>%
  group_by(period) %>%
  select(File, Date, Year,NAME, pH, DO, period, degx, degy, julianday) %>%
  mutate(is_pH_low = pH < 7.75,
         pH_event = label_events(is_pH_low),
        
         is_DO_low = DO < 4.6,
         DO_event = label_events(is_DO_low),
         
         is_pH_and_DO_low = ifelse(is_pH_low == TRUE & 
                                     is_DO_low == TRUE, TRUE, FALSE),
         pH_and_DO_event = label_events(is_pH_and_DO_low)) 
```

pH:

```{r}
#pH event summary
pH_event_summary <- events %>%
  filter(is_pH_low == TRUE) %>% 
  select(-DO_event, -DO, -is_DO_low, -is_pH_and_DO_low, -pH_and_DO_event) %>%
  group_by(File, pH_event) %>% 
  mutate(duration_days = n(),
         event_begin = min(Date),
         event_mean = mean(pH), #mean during the individual event 
         intensity = 7.75 - event_mean,
         severity = intensity*duration_days) %>%
  ungroup() %>%

  #mpa summary (across periods)
  group_by(File, period) %>%
  mutate(num_event = n_distinct(pH_event), 
         mean_event_duration = mean(duration_days),  
         max_event_duration = max(duration_days),
         mean_event_mean_pH = mean(event_mean), 
         mean_event_intensity = mean(intensity),
         mean_event_severity = mean(severity)) %>%
  ungroup() %>%

  #mpa summary (annual)
  group_by(File, Year, period) %>%
  mutate(annual_days_belowthresh = n(), annual_avg_ph_belowthresh = mean(pH)) %>%
  ungroup() %>%
  group_by(File, period) %>%
  mutate(meanannual_days_belowthresh = mean(annual_days_belowthresh),
         meanannual_avg_pH_belowthresh = mean(annual_avg_ph_belowthresh)) 
  
#now removing event-scale variables not needed to condense to mpa scale
pH_mpa_summary <- pH_event_summary %>%
  select(-duration_days, -event_begin, -event_mean, -intensity, 
         -severity, -is_pH_low,-pH_event, -julianday) %>%
  distinct(period, File, .keep_all = TRUE) %>%
  #renaming vars just for maps in next section
  rename("Mean num of events in a year" = "meanannual_days_belowthresh",
         "Mean pH during event"="meanannual_avg_pH_belowthresh")

#used later
pH_all_events <- left_join(events, pH_event_summary,
                         by = c("File", "Date", "Year", "NAME", "pH", 
                                "period", "degx", "degy", "julianday",
                                "is_pH_low", "pH_event"))
```

DO:

```{r}
#DO event summary
DO_event_summary <- events %>%
  filter(is_DO_low == TRUE) %>% 
  select(-pH_event, -pH, -is_pH_low, -is_pH_and_DO_low, -pH_and_DO_event) %>%
  group_by(File, DO_event) %>% 
  mutate(duration_days = n(),
         event_begin = min(Date),
         event_mean = mean(DO), #mean during the individual event 
         intensity = 7.75 - event_mean,
         severity = intensity*duration_days) %>%
  ungroup() %>%

  #mpa summary (across periods)
  group_by(File, period) %>%
  mutate(num_event = n_distinct(DO_event), 
         mean_event_duration = mean(duration_days),  
         max_event_duration = max(duration_days),
         mean_event_mean_pH = mean(event_mean), 
         mean_event_intensity = mean(intensity),
         mean_event_severity = mean(severity)) %>%
  ungroup() %>%

  #mpa summary (annual)
  group_by(File, Year, period) %>%
  mutate(annual_days_belowthresh = n(), annual_avg_DO_belowthresh = mean(DO)) %>%
  ungroup() %>%
  group_by(File, period) %>%
  mutate(meanannual_days_belowthresh = mean(annual_days_belowthresh),
         meanannual_avg_DO_belowthresh = mean(annual_avg_DO_belowthresh)) 
  
#now removing event-scale variables not needed to condense to mpa scale
DO_mpa_summary <- DO_event_summary %>% 
  select(-duration_days, -event_begin, -event_mean, -intensity, 
         -severity, -is_DO_low, -DO_event, -julianday) %>%
   distinct(File, period, .keep_all = TRUE) %>%
  #renaming vars just for maps in next section
  rename("Mean num of events in a year" = "meanannual_days_belowthresh",
         "Mean DO during event"= "meanannual_avg_DO_belowthresh")

#used later
DO_all_events <- left_join(events, DO_event_summary,
                         by = c("File", "Date", "Year", "NAME", "DO", 
                                "period", "degx", "degy", "julianday",
                                "is_DO_low", "DO_event"))
```

## Anomalous temp analysis

Categorized as anomalous event if temp exceeds historical climatology's temp for that month + 2\* hist clim sd

```{r}
#temp:
mpa_with_histclimsd <- mpa %>%
  filter(period == "historic") %>%
  group_by(File, Month) %>%
  summarise(hist_T_clim = mean(Temp), hist_T_clim_sd = sd(Temp)) %>% #this sd is temp over all days in Jan - rather than average of each jan's SD - does it make a difference? 
  merge(mpa, by = c("File", "Month"))

temp_event_summary <- mpa_with_histclimsd %>% 
  group_by(period) %>%
  select(File, Date, Year,NAME, Temp, hist_T_clim, hist_T_clim_sd, period, 
         degx, degy, julianday) %>%
  mutate(is_temp_high = Temp > (hist_T_clim + 2*hist_T_clim_sd),
         temp_event = label_events(is_temp_high)) %>%
  
  filter(is_temp_high == TRUE) %>%
  group_by(File, temp_event, period) %>% 
  mutate(duration_days = n(),
         event_begin = min(Date),
         event_mean = mean(Temp),  
         intensity = Temp - (hist_T_clim + 2*hist_T_clim_sd),
         severity = intensity*duration_days) %>%
  ungroup() %>%

  #mpa summary (across periods)
  group_by(File, period) %>%
  mutate(num_event = n_distinct(temp_event), 
         mean_event_duration = mean(duration_days),  
         max_event_duration = max(duration_days),
         mean_event_mean_temp = mean(event_mean), 
         mean_event_intensity = mean(intensity),
         mean_event_severity = mean(severity)) %>%
  ungroup() %>%
  
  #mpa summary (annual)
  group_by(File, Year, period) %>%
  mutate(annual_days_abovethresh = n(), 
         annual_avg_temp_abovethresh = mean(Temp)) %>%
  ungroup() %>%
  group_by(File, period) %>%
  mutate(meanannual_days_abovethresh = mean(annual_days_abovethresh),
         meanannual_avg_temp_abovethresh = mean(annual_avg_temp_abovethresh)) 
  
  #now removing event-scale variables not needed to condense to mpa scale
temp_mpa_summary <- temp_event_summary %>% 
  select(-Temp,-duration_days, -event_begin, -event_mean, -intensity, 
         -severity, -is_temp_high, -temp_event, -julianday) %>%
  distinct(period, File, .keep_all = TRUE) %>%
  #renaming vars just for maps in next section
  rename("Mean num of events in a year" = "meanannual_days_abovethresh",
         "Mean temperature during event"="meanannual_avg_temp_abovethresh")

#used later
temp_all_events <- left_join(mpa, temp_event_summary,
                         by = c("File", "Date", "Year", "NAME", "Temp", "period", 
                                "degx", "degy", "julianday"))
```

## Map of anom events

```{r}

CA_shp <- st_read(here("./data/rawdata/shp/CA_Counties/CA_Counties_TIGER2016.shp"))


make_anom_map <- function(mpa_summary_df, sumstat, periodt, title){
  
  anom_points <- st_as_sf((mpa_summary_df %>% filter(period == periodt)), 
                          coords = c("degx","degy"))
  
  
  #finding equal interval breaks based on all time periods
  all_breaks <- classInt::classIntervals(mpa_summary_df[[sumstat]], 10, "equal")
  
  tm_shape(CA_shp) + #basemap
   tm_fill(col = "#ccebc5") +
  
  tm_shape(anom_points) +
    tm_dots(col = sumstat, size = 0.05) +
          #,breaks = all_breaks$brks) +

  tm_layout(bg.color = "#a6cee3", 
            main.title = title,
            main.title.position = "center",
            main.title.size = .8,
            legend.title.size = .9,
            legend.text.size = .5)
  
}

make_anom_map(temp_mpa_summary, "Mean num of events in a year", "historic", 
              "Annual # of anomalous heat events in historic period") 

make_anom_map(temp_mpa_summary, "Mean num of events in a year", "midcen",
              "Annual # of anomalous heat events in mid century period") 

make_anom_map(temp_mpa_summary, "Mean num of events in a year", "endcen",
              "Annual # of anomalous heat events in end century period")


```

## Severity, Intensity, Duration

```{r}

#temp
temp_sev_int_dur <- function(periodt, site){
  
  plot <- temp_all_events %>%
    filter(period == periodt, NAME == site) %>%
    ggplot(aes(julianday, Year, fill = intensity)) +
    geom_tile() +
    scale_fill_distiller(palette = "YlOrRd", direction = 1, 
                         na.value = "skyblue") +
    theme_classic() +
    ggtitle(paste(periodt, "Heat events at", site)) 
    
ggsave(here(paste("./figs/sevintdur/","temp_events", periodt, site,".png",sep="_")), plot)

}

temp_sev_int_dur("historic", "Ano Nuevo SMR")
temp_sev_int_dur("midcen", "Ano Nuevo SMR")
temp_sev_int_dur("endcen", "Ano Nuevo SMR")
```

```{r}
#pH
pH_sev_int_dur <- function(periodt, site){
  
  plot <- pH_all_events %>%
    filter(period == periodt, NAME == site) %>%
    ggplot(aes(julianday, Year, fill = intensity)) +
    geom_tile() +
    scale_fill_distiller(palette = "YlOrRd", direction = 1, 
                         na.value = "skyblue") +
    theme_classic() +
    ggtitle(paste(periodt, "pH events at", site)) 
    
ggsave(here(paste("./figs/sevintdur/","pH_events", periodt, site,".png",sep="_")), plot)

}

pH_sev_int_dur("historic", "Ano Nuevo SMR")
pH_sev_int_dur("midcen", "Ano Nuevo SMR")
pH_sev_int_dur("endcen", "Ano Nuevo SMR")
```

```{r}
#DO
DO_sev_int_dur <- function(periodt, site){
  
  plot <- DO_all_events %>%
    filter(period == periodt, NAME == site) %>%
    ggplot(aes(julianday, Year, fill = intensity)) +
    geom_tile() +
    scale_fill_distiller(palette = "YlOrRd", direction = 1, 
                         na.value = "skyblue") +
    theme_classic() +
    ggtitle(paste(periodt, "DO events at", site)) 
    
ggsave(here(paste("./figs/sevintdur/","DO_events", periodt, site,".png",sep="_")), plot)

}

DO_sev_int_dur("historic", "Ano Nuevo SMR")
DO_sev_int_dur("midcen", "Ano Nuevo SMR")
DO_sev_int_dur("endcen", "Ano Nuevo SMR")
```

## Time series to put in context

```{r}

#this fig shows time series in julian days w/ envelope wrt given period's SD (NOT historic, as it should be for calculating anomalous event!)

make_temp_time_series <- function(periodt, site){

mpa %>% 
  filter(period == periodt, 
         NAME == site) %>%
  mutate(sliding_sd = roll_sd(Temp, 30, fill = NA)) %>% 
  group_by(julianday) %>%
  mutate(clim_mean = mean(Temp, na.rm = TRUE),
         clim_sd = mean(sliding_sd, na.rm = TRUE),
         clim_upr = clim_mean + 2 * clim_sd,
         clim_lwr = clim_mean - 2 * clim_sd) %>% 
  ungroup() %>%
  
  ggplot(aes(julianday)) +
  geom_ribbon(aes(ymin = clim_lwr, ymax = clim_upr),
              fill = "black", alpha = 0.75) +
  geom_line(aes(y = Temp, color = Year, group = Year),
            alpha = 0.5) +
  geom_line(aes(y = clim_mean), size = 1, color = "blue") +
  scale_color_viridis_c() +
  theme_classic() 
}

make_pH_time_series <- function(df, periodt, site){

df %>% 
  filter(period == periodt, 
         NAME == site) %>%
  mutate(sliding_sd = roll_sd(pH, 30, fill = NA)) %>% 
  group_by(julianday) %>%
  mutate(clim_mean = mean(pH, na.rm = TRUE),
         clim_sd = mean(sliding_sd, na.rm = TRUE),
         clim_upr = clim_mean + 2 * clim_sd,
         clim_lwr = clim_mean - 2 * clim_sd) %>% 
  ungroup() %>%
  
  ggplot(aes(julianday)) +
  geom_ribbon(aes(ymin = clim_lwr, ymax = clim_upr),
              fill = "black", alpha = 0.75) +
  geom_line(aes(y = pH, color = Year, group = Year),
            alpha = 0.5) +
  geom_line(aes(y = clim_mean), size = 1, color = "blue") +
  scale_color_viridis_c() +
  theme_classic() 
}

make_DO_time_series <- function(df, periodt, site){

df %>% 
  filter(period == periodt, 
         NAME == site) %>%
  mutate(sliding_sd = roll_sd(DO, 30, fill = NA)) %>% 
  group_by(julianday) %>%
  mutate(clim_mean = mean(DO, na.rm = TRUE),
         clim_sd = mean(sliding_sd, na.rm = TRUE),
         clim_upr = clim_mean + 2 * clim_sd,
         clim_lwr = clim_mean - 2 * clim_sd) %>% 
  ungroup() %>%
  
  ggplot(aes(julianday)) +
  geom_ribbon(aes(ymin = clim_lwr, ymax = clim_upr),
              fill = "black", alpha = 0.75) +
  geom_line(aes(y = DO, color = Year, group = Year),
            alpha = 0.5) +
  geom_line(aes(y = clim_mean), size = 1, color = "blue") +
  scale_color_viridis_c() +
  theme_classic() 
}



make_temp_time_series("historic","Ano Nuevo SMR") 
make_pH_time_series(mpa, "historic","Ano Nuevo SMR") 
make_DO_time_series(mpa, "historic","Ano Nuevo SMR") 


```

Making figs (severity/intensity/duration and time series for individual MPAs

```{r}

```
